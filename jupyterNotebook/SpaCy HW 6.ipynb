{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpaCy HW 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making sure it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Thrun PERSON\n",
      "Google ORG\n",
      "2007 DATE\n",
      "American NORP\n",
      "Thrun PERSON\n",
      "Recode ORG\n",
      "earlier this week DATE\n",
      "my fries were super gross my fries are such disgusting fries 0.806312154587466\n"
     ]
    }
   ],
   "source": [
    "text = (u\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        u\"Google in 2007, few people outside of the company took him \"\n",
    "        u\"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        u\"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        u\"worth talking to,” said Thrun, now the co-founder and CEO of \"\n",
    "        u\"online higher education startup Udacity, in an interview with \"\n",
    "        u\"Recode earlier this week.\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# Find named entities, phrases and concepts\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)\n",
    "\n",
    "# Determine semantic similarities\n",
    "doc1 = nlp(u\"my fries were super gross\")\n",
    "doc2 = nlp(u\"my fries are such disgusting fries\")\n",
    "similarity = doc1.similarity(doc2)\n",
    "print(doc1.text, doc2.text, similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going back to wikipedia entry for Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc=nlp(u\"\"\"Truth is most often used to mean being in accord with fact or reality, or fidelity to an original or standard.[1] Truth may also often be used in modern contexts to refer to an idea of \"truth to self,\" or authenticity.\n",
    "\n",
    "Truth is usually held to be opposite to falsehood, which, correspondingly, can also take on a logical, factual, or ethical meaning. The concept of truth is discussed and debated in several contexts, including philosophy, art, and religion. Many human activities depend upon the concept, where its nature as a concept is assumed rather than being a subject of discussion; these include most of the sciences, law, journalism, and everyday life. Some philosophers view the concept of truth as basic, and unable to be explained in any terms that are more easily understood than the concept of truth itself. Commonly, truth is viewed as the correspondence of language or thought to an independent reality, in what is sometimes called the correspondence theory of truth.\n",
    "\n",
    "Various theories and views of truth continue to be debated among scholars, philosophers, and theologians.[2] Language and words are a means by which humans convey information to one another and the method used to determine what is a \"truth\" is termed a criterion of truth. There are differing claims on such questions as what constitutes truth: what things are truthbearers capable of being true or false; how to define, identify, and distinguish truth; the roles that faith-based and empirically based knowledge play; and whether truth is subjective or objective, relative or absolute.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Truth is most often used to mean being in accord with fact or reality, or fidelity to an original or standard.[1] Truth may also often be used in modern contexts to refer to an idea of \"truth to self,\" or authenticity.\n",
       " ,\n",
       " Truth is usually held to be opposite to falsehood, which, correspondingly, can also take on a logical, factual, or ethical meaning.,\n",
       " The concept of truth is discussed and debated in several contexts, including philosophy, art, and religion.,\n",
       " Many human activities depend upon the concept, where its nature as a concept is assumed rather than being a subject of discussion; these include most of the sciences, law, journalism, and everyday life.,\n",
       " Some philosophers view the concept of truth as basic, and unable to be explained in any terms that are more easily understood than the concept of truth itself.,\n",
       " Commonly, truth is viewed as the correspondence of language or thought to an independent reality, in what is sometimes called the correspondence theory of truth.\n",
       " ,\n",
       " Various theories and views of truth continue to be debated among scholars, philosophers, and theologians.[2] Language and words are a means by which humans convey information to one another and the method used to determine what is a \"truth\" is termed a criterion of truth.,\n",
       " There are differing claims on such questions as what constitutes truth: what things are truthbearers capable of being true or false; how to define, identify, and distinguish truth; the roles that faith-based and empirically based knowledge play; and whether truth is subjective or objective, relative or absolute.]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth NOUN NN\n",
      "is VERB VBZ\n",
      "most ADV RBS\n",
      "often ADV RB\n",
      "used VERB VBN\n",
      "to PART TO\n",
      "mean VERB VB\n",
      "being VERB VBG\n",
      "in ADP IN\n",
      "accord NOUN NN\n",
      "with ADP IN\n",
      "fact NOUN NN\n",
      "or CCONJ CC\n",
      "reality NOUN NN\n",
      ", PUNCT ,\n",
      "or CCONJ CC\n",
      "fidelity NOUN NN\n",
      "to ADP IN\n",
      "an DET DT\n",
      "original ADJ JJ\n",
      "or CCONJ CC\n",
      "standard.[1 PROPN NNP\n",
      "] PUNCT -RRB-\n",
      "Truth PROPN NNP\n",
      "may VERB MD\n",
      "also ADV RB\n",
      "often ADV RB\n",
      "be VERB VB\n",
      "used VERB VBN\n",
      "in ADP IN\n",
      "modern ADJ JJ\n",
      "contexts NOUN NNS\n",
      "to PART TO\n",
      "refer VERB VB\n",
      "to ADP IN\n",
      "an DET DT\n",
      "idea NOUN NN\n",
      "of ADP IN\n",
      "\" PUNCT ``\n",
      "truth NOUN NN\n",
      "to ADP IN\n",
      "self NOUN NN\n",
      ", PUNCT ,\n",
      "\" PUNCT ''\n",
      "or CCONJ CC\n",
      "authenticity NOUN NN\n",
      ". PUNCT .\n",
      "\n",
      "\n",
      " SPACE _SP\n",
      "Truth PROPN NNP\n",
      "is VERB VBZ\n",
      "usually ADV RB\n",
      "held VERB VBN\n",
      "to PART TO\n",
      "be VERB VB\n",
      "opposite ADJ JJ\n",
      "to ADP IN\n",
      "falsehood NOUN NN\n",
      ", PUNCT ,\n",
      "which ADJ WDT\n",
      ", PUNCT ,\n",
      "correspondingly ADV RB\n",
      ", PUNCT ,\n",
      "can VERB MD\n",
      "also ADV RB\n",
      "take VERB VB\n",
      "on PART RP\n",
      "a DET DT\n",
      "logical ADJ JJ\n",
      ", PUNCT ,\n",
      "factual ADJ JJ\n",
      ", PUNCT ,\n",
      "or CCONJ CC\n",
      "ethical ADJ JJ\n",
      "meaning NOUN NN\n",
      ". PUNCT .\n",
      "The DET DT\n",
      "concept NOUN NN\n",
      "of ADP IN\n",
      "truth NOUN NN\n",
      "is VERB VBZ\n",
      "discussed VERB VBN\n",
      "and CCONJ CC\n",
      "debated VERB VBN\n",
      "in ADP IN\n",
      "several ADJ JJ\n",
      "contexts NOUN NNS\n",
      ", PUNCT ,\n",
      "including VERB VBG\n",
      "philosophy NOUN NN\n",
      ", PUNCT ,\n",
      "art NOUN NN\n",
      ", PUNCT ,\n",
      "and CCONJ CC\n",
      "religion NOUN NN\n",
      ". PUNCT .\n",
      "Many ADJ JJ\n",
      "human ADJ JJ\n",
      "activities NOUN NNS\n",
      "depend VERB VBP\n",
      "upon ADP IN\n",
      "the DET DT\n",
      "concept NOUN NN\n",
      ", PUNCT ,\n",
      "where ADV WRB\n",
      "its ADJ PRP$\n",
      "nature NOUN NN\n",
      "as ADP IN\n",
      "a DET DT\n",
      "concept NOUN NN\n",
      "is VERB VBZ\n",
      "assumed VERB VBN\n",
      "rather ADV RB\n",
      "than ADP IN\n",
      "being VERB VBG\n",
      "a DET DT\n",
      "subject NOUN NN\n",
      "of ADP IN\n",
      "discussion NOUN NN\n",
      "; PUNCT :\n",
      "these DET DT\n",
      "include VERB VBP\n",
      "most ADJ JJS\n",
      "of ADP IN\n",
      "the DET DT\n",
      "sciences NOUN NNS\n",
      ", PUNCT ,\n",
      "law NOUN NN\n",
      ", PUNCT ,\n",
      "journalism NOUN NN\n",
      ", PUNCT ,\n",
      "and CCONJ CC\n",
      "everyday ADJ JJ\n",
      "life NOUN NN\n",
      ". PUNCT .\n",
      "Some DET DT\n",
      "philosophers NOUN NNS\n",
      "view VERB VBP\n",
      "the DET DT\n",
      "concept NOUN NN\n",
      "of ADP IN\n",
      "truth NOUN NN\n",
      "as ADP IN\n",
      "basic ADJ JJ\n",
      ", PUNCT ,\n",
      "and CCONJ CC\n",
      "unable ADJ JJ\n",
      "to PART TO\n",
      "be VERB VB\n",
      "explained VERB VBN\n",
      "in ADP IN\n",
      "any DET DT\n",
      "terms NOUN NNS\n",
      "that ADJ WDT\n",
      "are VERB VBP\n",
      "more ADV RBR\n",
      "easily ADV RB\n",
      "understood VERB VBN\n",
      "than ADP IN\n",
      "the DET DT\n",
      "concept NOUN NN\n",
      "of ADP IN\n",
      "truth NOUN NN\n",
      "itself PRON PRP\n",
      ". PUNCT .\n",
      "Commonly ADV RB\n",
      ", PUNCT ,\n",
      "truth NOUN NN\n",
      "is VERB VBZ\n",
      "viewed VERB VBN\n",
      "as ADP IN\n",
      "the DET DT\n",
      "correspondence NOUN NN\n",
      "of ADP IN\n",
      "language NOUN NN\n",
      "or CCONJ CC\n",
      "thought VERB VBD\n",
      "to ADP IN\n",
      "an DET DT\n",
      "independent ADJ JJ\n",
      "reality NOUN NN\n",
      ", PUNCT ,\n",
      "in ADP IN\n",
      "what NOUN WP\n",
      "is VERB VBZ\n",
      "sometimes ADV RB\n",
      "called VERB VBN\n",
      "the DET DT\n",
      "correspondence NOUN NN\n",
      "theory NOUN NN\n",
      "of ADP IN\n",
      "truth NOUN NN\n",
      ". PUNCT .\n",
      "\n",
      "\n",
      " SPACE _SP\n",
      "Various ADJ JJ\n",
      "theories NOUN NNS\n",
      "and CCONJ CC\n",
      "views NOUN NNS\n",
      "of ADP IN\n",
      "truth NOUN NN\n",
      "continue VERB VBP\n",
      "to PART TO\n",
      "be VERB VB\n",
      "debated VERB VBN\n",
      "among ADP IN\n",
      "scholars NOUN NNS\n",
      ", PUNCT ,\n",
      "philosophers NOUN NNS\n",
      ", PUNCT ,\n",
      "and CCONJ CC\n",
      "theologians.[2 NOUN NN\n",
      "] PUNCT -RRB-\n",
      "Language PROPN NNP\n",
      "and CCONJ CC\n",
      "words NOUN NNS\n",
      "are VERB VBP\n",
      "a DET DT\n",
      "means NOUN NNS\n",
      "by ADP IN\n",
      "which ADJ WDT\n",
      "humans NOUN NNS\n",
      "convey VERB VBP\n",
      "information NOUN NN\n",
      "to ADP IN\n",
      "one NUM CD\n",
      "another DET DT\n",
      "and CCONJ CC\n",
      "the DET DT\n",
      "method NOUN NN\n",
      "used VERB VBD\n",
      "to PART TO\n",
      "determine VERB VB\n",
      "what NOUN WP\n",
      "is VERB VBZ\n",
      "a DET DT\n",
      "\" PUNCT ``\n",
      "truth NOUN NN\n",
      "\" PUNCT ''\n",
      "is VERB VBZ\n",
      "termed VERB VBN\n",
      "a DET DT\n",
      "criterion NOUN NN\n",
      "of ADP IN\n",
      "truth NOUN NN\n",
      ". PUNCT .\n",
      "There ADV EX\n",
      "are VERB VBP\n",
      "differing VERB VBG\n",
      "claims NOUN NNS\n",
      "on ADP IN\n",
      "such ADJ JJ\n",
      "questions NOUN NNS\n",
      "as ADP IN\n",
      "what NOUN WP\n",
      "constitutes VERB VBZ\n",
      "truth NOUN NN\n",
      ": PUNCT :\n",
      "what NOUN WP\n",
      "things NOUN NNS\n",
      "are VERB VBP\n",
      "truthbearers NOUN NNS\n",
      "capable ADJ JJ\n",
      "of ADP IN\n",
      "being VERB VBG\n",
      "true ADJ JJ\n",
      "or CCONJ CC\n",
      "false ADJ JJ\n",
      "; PUNCT :\n",
      "how ADV WRB\n",
      "to PART TO\n",
      "define VERB VB\n",
      ", PUNCT ,\n",
      "identify VERB VB\n",
      ", PUNCT ,\n",
      "and CCONJ CC\n",
      "distinguish VERB VB\n",
      "truth NOUN NN\n",
      "; PUNCT :\n",
      "the DET DT\n",
      "roles NOUN NNS\n",
      "that ADJ WDT\n",
      "faith NOUN NN\n",
      "- PUNCT HYPH\n",
      "based VERB VBN\n",
      "and CCONJ CC\n",
      "empirically ADV RB\n",
      "based VERB VBN\n",
      "knowledge NOUN NN\n",
      "play NOUN NN\n",
      "; PUNCT ,\n",
      "and CCONJ CC\n",
      "whether ADP IN\n",
      "truth NOUN NN\n",
      "is VERB VBZ\n",
      "subjective ADJ JJ\n",
      "or CCONJ CC\n",
      "objective ADJ JJ\n",
      ", PUNCT ,\n",
      "relative ADJ JJ\n",
      "or CCONJ CC\n",
      "absolute ADJ JJ\n",
      ". PUNCT .\n"
     ]
    }
   ],
   "source": [
    "for item in doc:\n",
    "    print(item.text, item.pos_, item.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's just focus on the Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth\n",
      "accord\n",
      "fact\n",
      "reality\n",
      "fidelity\n",
      "contexts\n",
      "idea\n",
      "truth\n",
      "self\n",
      "authenticity\n",
      "falsehood\n",
      "meaning\n",
      "concept\n",
      "truth\n",
      "contexts\n",
      "philosophy\n",
      "art\n",
      "religion\n",
      "activities\n",
      "concept\n",
      "nature\n",
      "concept\n",
      "subject\n",
      "discussion\n",
      "sciences\n",
      "law\n",
      "journalism\n",
      "life\n",
      "philosophers\n",
      "concept\n",
      "truth\n",
      "terms\n",
      "concept\n",
      "truth\n",
      "truth\n",
      "correspondence\n",
      "language\n",
      "reality\n",
      "what\n",
      "correspondence\n",
      "theory\n",
      "truth\n",
      "theories\n",
      "views\n",
      "truth\n",
      "scholars\n",
      "philosophers\n",
      "theologians.[2\n",
      "words\n",
      "means\n",
      "humans\n",
      "information\n",
      "method\n",
      "what\n",
      "truth\n",
      "criterion\n",
      "truth\n",
      "claims\n",
      "questions\n",
      "what\n",
      "truth\n",
      "what\n",
      "things\n",
      "truthbearers\n",
      "truth\n",
      "roles\n",
      "faith\n",
      "knowledge\n",
      "play\n",
      "truth\n",
      "is most often used to mean being in with or , or to an original or standard.[1 ] Truth may also often be used in modern to refer to an of \" to , \" or . \n",
      "\n",
      " Truth is usually held to be opposite to , which , correspondingly , can also take on a logical , factual , or ethical . The of is discussed and debated in several , including , , and . Many human depend upon the , where its as a is assumed rather than being a of ; these include most of the , , , and everyday . Some view the of as basic , and unable to be explained in any that are more easily understood than the of itself . Commonly , is viewed as the of or thought to an independent , in is sometimes called the of . \n",
      "\n",
      " Various and of continue to be debated among , , and ] Language and are a by which convey to one another and the used to determine is a \" \" is termed a of . There are differing on such as constitutes : are capable of being true or false ; how to define , identify , and distinguish ; the that - based and empirically based ; and whether is subjective or objective , relative or absolute .\n"
     ]
    }
   ],
   "source": [
    "truth=[]\n",
    "for item in doc:\n",
    "    if(str(item.pos_)== \"NOUN\"):\n",
    "        print(item)\n",
    "    else:\n",
    "        truth.append(str(item))\n",
    "        \n",
    "print(\" \".join(truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets talk in terms of mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vec(s):\n",
    "    return nlp.vocab[s].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.5076e-02, -4.6087e-01, -3.4570e-01, -2.4464e-01, -4.6808e-01,\n",
       "       -2.1032e-02,  2.7139e-01, -4.1686e-01,  8.1311e-01,  2.2596e-01,\n",
       "        5.7140e-02,  4.0233e-02, -2.2410e-01,  1.5497e-01,  4.7568e-01,\n",
       "        5.6356e-02, -1.1212e-01,  2.3747e+00, -6.4227e-01, -3.2498e-01,\n",
       "       -5.2689e-01, -2.7686e-01,  3.1064e-02, -4.7420e-01,  3.9213e-01,\n",
       "       -2.1971e-01, -6.1621e-01,  2.0757e-01,  5.3117e-01, -7.2091e-02,\n",
       "       -6.5013e-01, -1.7146e-01, -1.7652e-01,  4.8470e-01,  3.5410e-01,\n",
       "       -1.9164e-01,  3.5409e-01, -5.2345e-01, -4.0694e-01,  3.0467e-01,\n",
       "       -1.5172e-02,  3.2061e-01, -3.3203e-01, -2.6538e-01,  4.5404e-01,\n",
       "        1.2964e-01, -2.4249e-01,  2.9799e-01,  4.7481e-02, -2.8597e-01,\n",
       "       -5.3076e-01,  1.5943e-01, -2.7797e-01,  5.5911e-03, -5.7595e-02,\n",
       "       -4.8199e-01,  3.2368e-01, -3.7342e-01,  3.6967e-01, -4.2073e-01,\n",
       "        3.7729e-01,  4.6882e-01,  3.1315e-01, -2.4669e-01,  4.5771e-01,\n",
       "       -6.3025e-01, -4.2310e-01,  1.1754e-01,  2.0143e-01, -2.0812e-01,\n",
       "        5.3204e-01,  6.9480e-01,  1.5261e-01,  4.4947e-01, -1.4822e-01,\n",
       "       -6.6197e-01, -5.7918e-02, -2.0924e-01,  8.3096e-03, -2.9266e-01,\n",
       "       -9.4722e-02,  9.7406e-02, -3.1825e-01, -5.6527e-02,  2.8179e-02,\n",
       "       -5.8355e-01,  7.9790e-01,  6.5143e-01, -1.0187e-01, -2.5317e-01,\n",
       "       -4.3950e-02,  7.3545e-01, -3.7985e-01, -1.1667e-01, -6.7554e-02,\n",
       "       -4.8468e-01,  2.1814e-02, -1.9455e-01,  4.9753e-02,  7.4925e-01,\n",
       "        2.0740e-02,  4.1162e-01, -1.6648e-01, -2.3159e-01,  5.0135e-01,\n",
       "       -1.0817e+00, -5.1641e-01,  2.9149e-01,  5.8307e-04, -2.7735e-01,\n",
       "        1.8447e-01,  5.2183e-01,  4.2440e-01,  2.1159e-01,  3.3699e-01,\n",
       "       -1.1517e-01,  8.5168e-02, -4.7202e-01, -3.4705e-02,  1.3398e-01,\n",
       "        1.0577e-01, -3.1770e-01,  1.2579e+00,  2.0003e-01, -7.0777e-01,\n",
       "       -4.5362e-01, -2.9185e-01,  2.7059e-01, -3.9662e-01,  3.0565e-01,\n",
       "       -1.8057e-01, -5.6475e-02, -3.9085e-01,  5.9990e-01, -4.1243e-01,\n",
       "       -3.4531e-01, -1.9683e-01,  4.5799e-01,  7.9324e-02, -2.4491e-01,\n",
       "       -1.9753e+00, -9.5684e-02, -5.8243e-01,  9.1449e-02,  5.4621e-01,\n",
       "        3.4003e-01,  8.0573e-02, -5.2480e-02,  1.2914e-01,  1.7341e-01,\n",
       "        5.2574e-02, -3.4748e-01,  2.4869e-01,  1.1289e-02, -3.4162e-01,\n",
       "       -5.3844e-01,  1.4257e-01,  4.3625e-01, -4.2148e-01, -1.0306e+00,\n",
       "        2.1694e-01, -2.7787e-01, -2.9784e-01, -3.6926e-01, -2.9367e-01,\n",
       "       -4.9031e-01,  2.2310e-02, -4.0003e-01,  3.2349e-01,  3.2239e-01,\n",
       "        5.8328e-02,  9.1197e-01, -4.0291e-01,  2.0881e-01,  3.8923e-01,\n",
       "        4.9632e-03,  1.6204e-01, -2.9585e-01, -5.5759e-01,  9.4344e-02,\n",
       "       -3.5399e-01,  5.5062e-03,  7.8812e-01,  1.4054e-01,  3.5202e-01,\n",
       "       -4.7126e-01,  4.4977e-01, -2.4998e-01,  1.7796e-01, -4.3415e-01,\n",
       "       -5.8656e-01, -5.2898e-01,  2.5488e-01, -1.7707e-03,  5.0335e-01,\n",
       "       -6.2458e-02,  2.5743e-01, -1.2153e-01, -2.7211e-01,  1.0273e-02,\n",
       "       -7.5346e-01,  1.7385e-01, -2.6741e-01, -2.9186e-01,  3.1044e-01,\n",
       "        1.8223e-01,  4.3421e-01,  4.9220e-02,  2.0894e-01, -5.5592e-01,\n",
       "        4.4125e-01, -8.1337e-02, -1.4260e-01, -8.5250e-02,  9.3076e-02,\n",
       "       -8.2719e-01,  1.8974e-01,  3.5319e-01, -5.2029e-01,  1.4852e-01,\n",
       "        1.8475e-01, -6.3992e-01, -5.0221e-01, -2.8240e-01, -2.3502e-01,\n",
       "        2.5481e-01,  8.7516e-01,  5.6299e-01,  5.5404e-01,  7.9143e-02,\n",
       "       -7.9138e-01,  1.8097e-01,  3.1675e-01,  5.5448e-02,  1.7308e-01,\n",
       "        1.9333e-01, -1.6469e-01,  2.5557e-01,  8.2517e-01,  4.5646e-01,\n",
       "        1.6291e-02,  2.3285e-01,  5.0195e-01, -2.4031e-01, -6.5860e-03,\n",
       "       -6.4105e-01,  1.3116e-01, -3.0964e-01, -5.4616e-01,  2.6518e-01,\n",
       "       -1.8569e-01, -3.5930e-01, -2.8354e-02,  4.5558e-01,  6.7682e-01,\n",
       "       -3.4866e-01, -3.2562e-01,  1.7719e-01,  7.9438e-01, -2.4378e-03,\n",
       "        3.4581e-01,  2.9165e-01,  2.5604e-01, -6.9598e-01, -1.2522e-01,\n",
       "        2.1538e-01, -2.4784e-02,  2.7704e-02,  1.0209e+00,  2.5637e-01,\n",
       "       -2.4139e-01, -6.8379e-02, -7.9083e-02,  1.0063e-01, -1.3907e-01,\n",
       "       -1.6053e-01,  2.0665e-01, -1.7786e-01, -2.8881e-01, -1.2980e-01,\n",
       "        4.3785e-01,  2.2667e-01,  1.5608e-01, -9.2884e-02,  3.1360e-01,\n",
       "       -3.1150e-01,  3.3414e-01, -1.3245e-01, -2.1574e-01, -2.9748e-01,\n",
       "       -3.8886e-01,  4.8880e-01,  4.9199e-02,  8.9116e-03,  1.6376e-01,\n",
       "       -2.1425e-01, -2.5160e-01,  2.2319e-01, -1.8565e-01,  3.2559e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec(\"mouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# cosine similarity\n",
    "def cosine(v1, v2):\n",
    "    if norm(v1) > 0 and norm(v2) > 0:\n",
    "        return dot(v1, v2) / (norm(v1) * norm(v2))\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtractv(coord1, coord2):\n",
    "    return [c1 - c2 for c1, c2 in zip(coord1, coord2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-5, 1, -6, 2]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtractv( [5, 2,4,3],[10, 1,10,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.381276,\n",
       " -0.79262996,\n",
       " -0.384451,\n",
       " -0.43376,\n",
       " -0.09184003,\n",
       " -0.05505,\n",
       " 0.33748198,\n",
       " -1.0229601,\n",
       " 0.754115,\n",
       " -2.60924,\n",
       " 0.13426399,\n",
       " -0.115737006,\n",
       " 0.0006700009,\n",
       " -0.05748999,\n",
       " 0.74593997,\n",
       " -0.025311995,\n",
       " 0.18621,\n",
       " 1.9837501,\n",
       " -0.18327004,\n",
       " -0.63452,\n",
       " -1.0963199,\n",
       " -0.07439999,\n",
       " -0.288666,\n",
       " -0.60712004,\n",
       " 0.16396,\n",
       " -0.043160006,\n",
       " -0.75904,\n",
       " 0.166489,\n",
       " 0.72393,\n",
       " -0.238761,\n",
       " -0.567499,\n",
       " -0.81636,\n",
       " 0.15106998,\n",
       " 0.31489998,\n",
       " 0.02590999,\n",
       " -0.44625998,\n",
       " 0.430507,\n",
       " -0.585303,\n",
       " -0.12032002,\n",
       " 0.16988,\n",
       " 0.043293,\n",
       " 0.5959,\n",
       " -0.060409993,\n",
       " -0.38785,\n",
       " 0.384461,\n",
       " 0.147754,\n",
       " -0.35375,\n",
       " 0.37809598,\n",
       " 0.08628,\n",
       " -0.243686,\n",
       " -0.48658597,\n",
       " -0.39913002,\n",
       " 0.16454002,\n",
       " -0.0299739,\n",
       " -0.195015,\n",
       " -0.399161,\n",
       " 0.43359,\n",
       " -0.64317,\n",
       " 0.20882,\n",
       " -0.33813298,\n",
       " 0.54478,\n",
       " 0.61092,\n",
       " 0.10663998,\n",
       " 0.34597,\n",
       " 0.430236,\n",
       " -0.596649,\n",
       " -0.27454,\n",
       " 0.43385,\n",
       " 0.31256998,\n",
       " 0.049889997,\n",
       " 0.92159,\n",
       " 0.63110703,\n",
       " -0.40898,\n",
       " 0.511379,\n",
       " -0.030300006,\n",
       " -0.78358,\n",
       " -0.159058,\n",
       " -0.05689001,\n",
       " 0.1514896,\n",
       " -0.72239,\n",
       " -0.01941,\n",
       " 0.229186,\n",
       " -0.02193001,\n",
       " 0.154193,\n",
       " -0.330201,\n",
       " 0.035109997,\n",
       " 0.851938,\n",
       " 1.66043,\n",
       " -0.010996997,\n",
       " -0.24896692,\n",
       " 0.14556,\n",
       " 0.87323004,\n",
       " 0.25109002,\n",
       " -0.35007,\n",
       " -0.10912199,\n",
       " -0.82674,\n",
       " 0.46007398,\n",
       " 0.13245,\n",
       " 0.155443,\n",
       " 1.41591,\n",
       " -0.48537,\n",
       " 0.52625,\n",
       " -0.45738,\n",
       " -0.271243,\n",
       " 0.14976999,\n",
       " 0.11750007,\n",
       " -0.5143283,\n",
       " -0.08299002,\n",
       " 0.64643306,\n",
       " -0.86234003,\n",
       " 0.44317,\n",
       " 0.08089003,\n",
       " 0.55476,\n",
       " 0.96358,\n",
       " 0.289285,\n",
       " -0.62063,\n",
       " 0.414668,\n",
       " -0.4624444,\n",
       " -0.25431502,\n",
       " 0.40978,\n",
       " 0.165499,\n",
       " -0.049250007,\n",
       " 1.4345,\n",
       " -0.12450001,\n",
       " -1.10237,\n",
       " 0.08805999,\n",
       " 0.034969985,\n",
       " 0.76586,\n",
       " -0.304137,\n",
       " 0.958,\n",
       " -0.57267,\n",
       " 0.028649002,\n",
       " -0.3922388,\n",
       " 1.00185,\n",
       " -0.460654,\n",
       " -0.69816,\n",
       " -0.07869001,\n",
       " 0.545141,\n",
       " 0.065481,\n",
       " 0.14256,\n",
       " 0.0032000542,\n",
       " 0.054686002,\n",
       " -0.630071,\n",
       " -0.23841101,\n",
       " 0.81536996,\n",
       " 0.48788002,\n",
       " 0.013343997,\n",
       " -0.21117,\n",
       " 0.2723,\n",
       " 0.55291,\n",
       " 0.240414,\n",
       " 0.11555001,\n",
       " -0.24668,\n",
       " 0.027989,\n",
       " -0.432442,\n",
       " -0.77694,\n",
       " 0.42927003,\n",
       " 1.20178,\n",
       " 0.04833001,\n",
       " -1.13281,\n",
       " 0.09644,\n",
       " -0.14716999,\n",
       " -0.52077997,\n",
       " -1.13294,\n",
       " -0.40232,\n",
       " -0.78864,\n",
       " 0.23174,\n",
       " -0.029949993,\n",
       " 0.53599,\n",
       " 0.26172298,\n",
       " 0.0544553,\n",
       " 1.37988,\n",
       " -0.92028,\n",
       " 0.8622,\n",
       " 0.16654001,\n",
       " -0.1863468,\n",
       " 0.256198,\n",
       " -0.020770013,\n",
       " -0.35846,\n",
       " 0.239124,\n",
       " -0.49184,\n",
       " 0.0961932,\n",
       " 0.64267,\n",
       " 0.030260004,\n",
       " 0.22707,\n",
       " -0.65895003,\n",
       " 0.70203,\n",
       " -0.0038300008,\n",
       " -0.22432001,\n",
       " -0.62668,\n",
       " -0.20876002,\n",
       " -0.39412004,\n",
       " 0.324772,\n",
       " -0.2633407,\n",
       " 0.70675004,\n",
       " -0.257238,\n",
       " 0.42712998,\n",
       " 0.17886001,\n",
       " -0.44101,\n",
       " -0.562257,\n",
       " -0.53957,\n",
       " 0.133331,\n",
       " 0.122509986,\n",
       " -0.17043,\n",
       " 0.71042,\n",
       " 0.221508,\n",
       " 0.25728,\n",
       " 0.23979,\n",
       " 0.31955,\n",
       " -0.98211,\n",
       " 0.68005,\n",
       " 0.082153,\n",
       " -0.196213,\n",
       " -0.14931199,\n",
       " -0.082494,\n",
       " -0.27476996,\n",
       " 0.1816029,\n",
       " 0.3543664,\n",
       " 0.10035998,\n",
       " 0.57644,\n",
       " 0.13373001,\n",
       " -0.85783,\n",
       " -0.36532003,\n",
       " -0.298076,\n",
       " -0.38975,\n",
       " -0.093899995,\n",
       " 1.0306,\n",
       " 0.4526,\n",
       " 0.66591,\n",
       " 0.051517002,\n",
       " -0.842686,\n",
       " 0.211615,\n",
       " 0.41684,\n",
       " -0.054922003,\n",
       " 0.49489,\n",
       " 0.37155002,\n",
       " -0.196403,\n",
       " 0.277041,\n",
       " 1.21428,\n",
       " 0.36512,\n",
       " -0.153029,\n",
       " 0.67813,\n",
       " 0.534043,\n",
       " 0.37224,\n",
       " -0.179206,\n",
       " -0.42812997,\n",
       " -0.14507999,\n",
       " 0.034130007,\n",
       " -0.45143998,\n",
       " 0.074719995,\n",
       " -0.59037,\n",
       " -0.32376698,\n",
       " -0.028409628,\n",
       " 0.98500997,\n",
       " 0.99257,\n",
       " -0.67873,\n",
       " -0.59803,\n",
       " 0.255676,\n",
       " 0.64541,\n",
       " -0.0111024,\n",
       " 0.61812997,\n",
       " 0.43471998,\n",
       " 0.46147,\n",
       " -1.04266,\n",
       " -0.218979,\n",
       " 0.43879998,\n",
       " -0.58163404,\n",
       " -0.507806,\n",
       " 0.45814002,\n",
       " 0.338627,\n",
       " -0.115030006,\n",
       " -0.327919,\n",
       " 0.374147,\n",
       " 0.19531101,\n",
       " -0.52693,\n",
       " 0.039020002,\n",
       " 0.14405301,\n",
       " -0.44130003,\n",
       " -0.12705001,\n",
       " -0.21776,\n",
       " 0.20475,\n",
       " 0.42728,\n",
       " -0.14617,\n",
       " 0.271006,\n",
       " 0.27294502,\n",
       " -0.56178,\n",
       " 0.6491,\n",
       " -0.33697,\n",
       " -0.06784999,\n",
       " -0.330145,\n",
       " -0.19014,\n",
       " 0.515543,\n",
       " 0.426239,\n",
       " 0.1538316,\n",
       " -0.004859999,\n",
       " -0.3346,\n",
       " -0.55588996,\n",
       " 0.061419994,\n",
       " -0.281632,\n",
       " 0.23528802]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtractv(vec(\"mouse\"), vec(\"truth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, I get a number but what does that mean in words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "closest(colors, subtractv(colors['purple'], colors['red']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar(word):\n",
    "    by_similarity = sorted(word.vocab, key=lambda w: word.similarity(w), reverse=True)\n",
    "    return [w.orth_ for w in by_similarity[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:59.314198\n",
      "['dog', 'HOUND', 'Kennel', 'DOG', 'kennel', 'canine', 'DoG', 'Dog', 'doG', 'KENNEL']\n"
     ]
    }
   ],
   "source": [
    "now=datetime.datetime.now()\n",
    "similar=most_similar(nlp.vocab[u'dog'])\n",
    "print(datetime.datetime.now()-now)\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wow, that was slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab[u'dog'].cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perhaps I need to grab a smaller text? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spacy_closest(token_list, vec_to_check, n=10):\n",
    "    return sorted(token_list,\n",
    "                  key=lambda x: cosine(vec_to_check, vec(x)),\n",
    "                  reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related(word):\n",
    "    filtered_words = [w for w in word.vocab if w.is_lower == word.is_lower and w.prob >= -15]\n",
    "    similarity = sorted(filtered_words, key=lambda w: word.similarity(w), reverse=True)\n",
    "    return similarity[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plane', 'planes', 'airplane', 'airliner', 'glider', 'winging', 'flying', 'flight', 'airfield', 'airspace']\n",
      "0:00:02.300324\n"
     ]
    }
   ],
   "source": [
    "now=datetime.datetime.now()\n",
    "similar_words=get_related(nlp.vocab[u'plane'])\n",
    "print ([w.lower_ for w in similar_words])\n",
    "print(datetime.datetime.now()-now)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OH!!! this looks promesing, only 2.3s\n",
    "now lets try to get a word from a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_balck_minus_white=subtractv(vec(\"mouse\"), vec(\"truth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab.set_vector('word_to_test', vec_balck_minus_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mouse', 'mice', 'cursor', 'indent', 'left/right', 'joystick', 'wiimote', 'joysticks', 'stylus', 'gyro']\n",
      "0:00:01.896567\n"
     ]
    }
   ],
   "source": [
    "now=datetime.datetime.now()\n",
    "similar_words=get_related(nlp.vocab['word_to_test'])\n",
    "print ([w.lower_ for w in similar_words])\n",
    "print(datetime.datetime.now()-now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mouse', 'mice', 'rodent', 'rat', 'cursor', 'indent', 'keypad', 'keyboard', 'touchpad', 'rabbit']\n",
      "0:00:02.253621\n"
     ]
    }
   ],
   "source": [
    "now=datetime.datetime.now()\n",
    "similar_words=get_related(nlp.vocab['mouse'])\n",
    "print ([w.lower_ for w in similar_words])\n",
    "print(datetime.datetime.now()-now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hmmm this is clearly not working the way I expected\n",
    "I think it is the substractv that is not working but that is strange, I think this would be the simplest part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def meanv(coords):\n",
    "    # assumes every item in coords has same length as item 0\n",
    "    sumv = [0] * len(coords[0])\n",
    "    for item in coords:\n",
    "        for i in range(len(item)):\n",
    "            sumv[i] += item[i]\n",
    "    mean = [0] * len(sumv)\n",
    "    for i in range(len(sumv)):\n",
    "        mean[i] = float(sumv[i]) / len(coords)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg=meanv([vec(\"mouse\"),vec(\"truth\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab.set_vector(u'word_to_test', avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mouse', 'truth', 'human', 'nothing', 'thing', 'mind', 'whatever', 'reason', 'that', 'fact']\n",
      "0:00:01.869188\n"
     ]
    }
   ],
   "source": [
    "now=datetime.datetime.now()\n",
    "similar_words=get_related(nlp.vocab[u'word_to_test'])\n",
    "print ([w.lower_ for w in similar_words])\n",
    "print(datetime.datetime.now()-now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still not great but slightly at least more interesing...\n",
    "\n",
    "Going back to wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that is most often used to mean being in human with mice or mouse , or ability to an original or standard.[1 ] Truth may also often be used in modern mouse to refer to an thing of \" mind to self , \" or keypad . \n",
      "\n",
      " Truth is usually held to be opposite to deception , which , correspondingly , can also take on a logical , factual , or ethical keyboard . The rat of that is discussed and debated in several mouse , including concept , sketching , and religion . Many human activity depend upon the mice , where its animal as a idea is assumed rather than being a subject of rodent ; these include most of the biology , human , journalism , and everyday mice . Some mouse view the rodent of truth as basic , and unable to be explained in any keypad that are more easily understood than the keypad of that itself . Commonly , whatever is viewed as the letters of language or thought to an independent rat , in that is sometimes called the typed hypotheses of nothing . \n",
      "\n",
      " Various human and touchpad of nothing continue to be debated among scholars , philosopher , and cursor ] Language and keyboard are a cursor by which rats convey directly to one another and the methods used to determine something is a \" human \" is termed a specific of truth . There are differing claiming on such questions as something constitutes truth : mouse thing are keyboard capable of being true or false ; how to define , identify , and distinguish fact ; the functions that belief - based and empirically based computer player ; and whether that is subjective or objective , relative or absolute .\n"
     ]
    }
   ],
   "source": [
    "modifier=\"mouse\"\n",
    "truth=[]\n",
    "for item in doc:\n",
    "    if(str(item.pos_)== \"NOUN\"):\n",
    "        avg=meanv([vec(modifier),vec(str(item))])\n",
    "        nlp.vocab.set_vector(u'word_to_test', avg)\n",
    "        similar_words=get_related(nlp.vocab[u'word_to_test'])\n",
    "        truth.append(str(random.choice([w.lower_ for w in similar_words])))\n",
    "    else:\n",
    "        truth.append(str(item))\n",
    "        \n",
    "print(\" \".join(truth))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
